{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03f4e0ba-06d3-4264-8ebd-1754ce203752",
   "metadata": {},
   "source": [
    "# INMS - sniffing the sky\n",
    "\n",
    "The Ion Neutral Mass Spectrometer sniffs space to analyze what chemicals are out there. It ionizes matter with electron beam and produces a spectrum via a quadrupole (collection of four steel rods with electrical currents running through). As part of the analysis metadata, positional data is recorded. Cross-referenced with the mission plan, we can find the closest flybys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1252b1ba-c5cf-4961-84bd-c74965936af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e15dd157-a04f-4f7c-a81d-f863880360bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\"../.env\")\n",
    "user = os.environ.get('POSTGRES_USER')\n",
    "pw = os.environ.get('POSTGRES_PASSWORD')\n",
    "db_name = os.environ.get('POSTGRES_DB')\n",
    "host = 'localhost'\n",
    "port = 5432\n",
    "conn_str = f'postgresql://{user}:{pw}@{host}:{port}/{db_name}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fee2fcb6-2e5b-4af3-b0ee-37aa6029148a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a81adb35-49f9-4f52-8cbf-d0ac0acbeddb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%sql $conn_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c584f08-6795-4845-8bff-787a7e0f6d85",
   "metadata": {},
   "source": [
    "## dataset structure\n",
    "\n",
    "due to the large size, need to be selective on which files to use. INMS is separated to folders of years, months, days of year, and then a mess of CSVs. We need to limit our search by figuring out the year/day of year for each suspected flyby. Use our `enceladus_events` materialized view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbd95d9e-de77-4aa5-9f84-a4853c5cbc40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://postgres:***@localhost:5432/enceladus\n",
      "24 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>date_part</th>\n",
       "            <th>to_char</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>2005.0</td>\n",
       "            <td>048</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2005.0</td>\n",
       "            <td>068</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2005.0</td>\n",
       "            <td>195</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2008.0</td>\n",
       "            <td>072</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2008.0</td>\n",
       "            <td>224</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2008.0</td>\n",
       "            <td>283</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2008.0</td>\n",
       "            <td>305</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2009.0</td>\n",
       "            <td>306</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2009.0</td>\n",
       "            <td>306</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2009.0</td>\n",
       "            <td>325</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2010.0</td>\n",
       "            <td>117</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2010.0</td>\n",
       "            <td>138</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2010.0</td>\n",
       "            <td>225</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2010.0</td>\n",
       "            <td>334</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2010.0</td>\n",
       "            <td>355</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2011.0</td>\n",
       "            <td>274</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2011.0</td>\n",
       "            <td>292</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2011.0</td>\n",
       "            <td>310</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2012.0</td>\n",
       "            <td>087</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2012.0</td>\n",
       "            <td>105</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2012.0</td>\n",
       "            <td>123</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2015.0</td>\n",
       "            <td>287</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2015.0</td>\n",
       "            <td>301</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2015.0</td>\n",
       "            <td>353</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[(2005.0, '048'),\n",
       " (2005.0, '068'),\n",
       " (2005.0, '195'),\n",
       " (2008.0, '072'),\n",
       " (2008.0, '224'),\n",
       " (2008.0, '283'),\n",
       " (2008.0, '305'),\n",
       " (2009.0, '306'),\n",
       " (2009.0, '306'),\n",
       " (2009.0, '325'),\n",
       " (2010.0, '117'),\n",
       " (2010.0, '138'),\n",
       " (2010.0, '225'),\n",
       " (2010.0, '334'),\n",
       " (2010.0, '355'),\n",
       " (2011.0, '274'),\n",
       " (2011.0, '292'),\n",
       " (2011.0, '310'),\n",
       " (2012.0, '087'),\n",
       " (2012.0, '105'),\n",
       " (2012.0, '123'),\n",
       " (2015.0, '287'),\n",
       " (2015.0, '301'),\n",
       " (2015.0, '353')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "select \n",
    "    date_part('year', date), \n",
    "    to_char(time_stamp, 'DDD')\n",
    "from enceladus_events\n",
    "where event like '%closest%'\n",
    "order by time_stamp;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58ab3fe-2af3-46ca-b766-f8d457280a16",
   "metadata": {},
   "source": [
    "The dataset includes a FMT file which is a manifest describes the CSV columns\n",
    "\n",
    "- `ALT_T` - altitude of spacecraft above target body within 1 hour of closest flyby\n",
    "- `TARGET` - target body\n",
    "\n",
    "Search for `TARGET = 'enceladus` and look for lowest `ALT_T`?\n",
    "\n",
    "## CSVs and bash\n",
    "\n",
    "- `ls ./**/*/.csv | wc -l`\n",
    "  - lists all CSVs, pipe output to wordcount, count only lines\n",
    "  - return num of CSVs\n",
    "  - loop over each CSV and run `COPY FROM`?\n",
    "  - or concat into single CSV, then import?\n",
    "  - second is better to avoid partially copied table, in case of failure\n",
    "- `cat ./**/*.csv > inms.csv`\n",
    "  - what are the CSV headers?\n",
    "    - rows 1-3 are headers\n",
    "    - remove from each CSV?\n",
    "    - import as is and remove with SQL\n",
    "  - do all CSVs have same headers\n",
    "- `csvkit` has useful tools for importing CSVs to db\n",
    "  - `csvsql` takes a csv and generate a `CREATE TABLE` SQL statement\n",
    "    - defaults all the VARCHAR but it takes up more space than TEXT\n",
    "    - TEXT is same as VARCHAR in postgres, but has no length check and so is faster\n",
    "    - use `sed` to convert VARCHAR to text\n",
    "   \n",
    "```bash\n",
    "csvsql 2005/048/200504800_L1A_05.csv \\\n",
    "    -i postgresql \\\n",
    "    --tables \"import.inms\" \\\n",
    "    --no-constraints \\\n",
    "    -overwrite | sed 's/VARCHAR/text/g' > import.sql\n",
    "```\n",
    "\n",
    "Use this template to \n",
    "\n",
    "- add `DROP ... IF EXISTS`\n",
    "- `COPY FROM` at the end\n",
    "- change table name; we want to create this in the `import` schema, but if we run `import.sql` it will create `import.inms` in `public` schema, so we'll change the `import.sql` file manually to correct for this\n",
    "\n",
    "### error: extra data\n",
    "\n",
    "2015 suddenly added a bunch of new columns which failed the import, since we used 2005 csv as the template to create our table. Manifest explains the new columns.\n",
    "\n",
    "Options:\n",
    "\n",
    "1. cut the extra columns - `cut -d -f2 --complement inms.csv`\n",
    "1. load 2015 as separate table?\n",
    "   \n",
    "Best to cut the extra columns from 2015 csv after visual inspection with excel\n",
    "\n",
    "\n",
    "```bash\n",
    "cat 2015/**/*.csv > 2015.csv\n",
    "cut -d ',' -f1,3-47,50-77,82-83 2015.csv > inms_2.csv\n",
    "\n",
    "# manually move all other years into ./good/\n",
    "cat good/**/*.csv > inms_1.csv\n",
    "\n",
    "# combine to one\n",
    "cat inms_1.csv inms_2.csv > inms.csv\n",
    "```\n",
    "\n",
    "- import with `psql enceladus < import.sql`\n",
    "- Remove all the header rows with SQL - `delete from import.inms where sclk='sclk';`\n",
    "- remove all entries without `sclk`, or spacecraft clock, data - `delete from import.inms where sclk is null or sclk='';`\n",
    "- try to look for all entries with enceladus as target and create view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884c8a73-2651-437d-a521-29df5d4d915d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "-- remove header rows (artifact of concatenation)\n",
    "delete from import.inms where sclk='sclk';\n",
    "\n",
    "-- remove null timestamp entries\n",
    "delete from import.inms where sclk is null or sclk='';\n",
    "\n",
    "-- create view for enceladus\n",
    "drop materialized view if exists flyby_altitudes;\n",
    "create materialized view flyby_altitudes as\n",
    "select\n",
    "    (sclk::timestamp) as time_stamp,\n",
    "    alt_t::numeric(10,3) as altitude\n",
    "from import.inms\n",
    "where target='ENCELADUS'\n",
    "and alt_t IS NOT NULL;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c75ccd6-e578-4d55-b44f-680d41b25851",
   "metadata": {},
   "source": [
    "## INMS data inspection\n",
    "\n",
    "lowest point of each flyby:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5897e62f-ef21-4cf5-a4a9-ed93d80d1007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://postgres:***@localhost:5432/enceladus\n",
      "(psycopg2.errors.GroupingError) column \"flyby_altitudes.time_stamp\" must appear in the GROUP BY clause or be used in an aggregate function\n",
      "LINE 1: select time_stamp,\n",
      "               ^\n",
      "\n",
      "[SQL: select time_stamp,\n",
      "min(altitude)\n",
      "from flyby_altitudes\n",
      "group by DATE(time_stamp)\n",
      "order by min(altitude);]\n",
      "(Background on this error at: https://sqlalche.me/e/20/f405)\n"
     ]
    }
   ],
   "source": [
    "%%sql\n",
    "select time_stamp,\n",
    "min(altitude)\n",
    "from flyby_altitudes\n",
    "group by DATE(time_stamp)\n",
    "order by min(altitude);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5623c1e-72f8-4883-8b70-1bc3f0344660",
   "metadata": {},
   "source": [
    "## nadirs\n",
    "\n",
    "To find the closest flyby from `flyby_altitudes`, we look for `min(altitude)` grouped by weeks, given that flybys must be at least two weeks apart for cassini to slingshot around saturn or titan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8137afdf-a86c-496c-9429-2aebcc4f2851",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://postgres:***@localhost:5432/enceladus\n",
      "23 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>year</th>\n",
       "            <th>week</th>\n",
       "            <th>altitude</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>2005</td>\n",
       "            <td>7</td>\n",
       "            <td>1272.075</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2005</td>\n",
       "            <td>10</td>\n",
       "            <td>500.370</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2005</td>\n",
       "            <td>28</td>\n",
       "            <td>168.012</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2008</td>\n",
       "            <td>11</td>\n",
       "            <td>50.292</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2008</td>\n",
       "            <td>33</td>\n",
       "            <td>53.353</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2008</td>\n",
       "            <td>41</td>\n",
       "            <td>28.576</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2008</td>\n",
       "            <td>44</td>\n",
       "            <td>173.044</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2009</td>\n",
       "            <td>45</td>\n",
       "            <td>98.901</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2009</td>\n",
       "            <td>47</td>\n",
       "            <td>1596.561</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2010</td>\n",
       "            <td>17</td>\n",
       "            <td>3771.195</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2010</td>\n",
       "            <td>20</td>\n",
       "            <td>437.292</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2010</td>\n",
       "            <td>32</td>\n",
       "            <td>2555.180</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2010</td>\n",
       "            <td>48</td>\n",
       "            <td>45.699</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2010</td>\n",
       "            <td>51</td>\n",
       "            <td>48.324</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2011</td>\n",
       "            <td>39</td>\n",
       "            <td>98.898</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2011</td>\n",
       "            <td>42</td>\n",
       "            <td>1230.674</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2011</td>\n",
       "            <td>44</td>\n",
       "            <td>496.603</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2012</td>\n",
       "            <td>13</td>\n",
       "            <td>74.165</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2012</td>\n",
       "            <td>15</td>\n",
       "            <td>74.100</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2012</td>\n",
       "            <td>18</td>\n",
       "            <td>73.134</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2015</td>\n",
       "            <td>42</td>\n",
       "            <td>1844.230</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2015</td>\n",
       "            <td>44</td>\n",
       "            <td>49.010</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2015</td>\n",
       "            <td>51</td>\n",
       "            <td>5000.200</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[(2005, 7, Decimal('1272.075')),\n",
       " (2005, 10, Decimal('500.370')),\n",
       " (2005, 28, Decimal('168.012')),\n",
       " (2008, 11, Decimal('50.292')),\n",
       " (2008, 33, Decimal('53.353')),\n",
       " (2008, 41, Decimal('28.576')),\n",
       " (2008, 44, Decimal('173.044')),\n",
       " (2009, 45, Decimal('98.901')),\n",
       " (2009, 47, Decimal('1596.561')),\n",
       " (2010, 17, Decimal('3771.195')),\n",
       " (2010, 20, Decimal('437.292')),\n",
       " (2010, 32, Decimal('2555.180')),\n",
       " (2010, 48, Decimal('45.699')),\n",
       " (2010, 51, Decimal('48.324')),\n",
       " (2011, 39, Decimal('98.898')),\n",
       " (2011, 42, Decimal('1230.674')),\n",
       " (2011, 44, Decimal('496.603')),\n",
       " (2012, 13, Decimal('74.165')),\n",
       " (2012, 15, Decimal('74.100')),\n",
       " (2012, 18, Decimal('73.134')),\n",
       " (2015, 42, Decimal('1844.230')),\n",
       " (2015, 44, Decimal('49.010')),\n",
       " (2015, 51, Decimal('5000.200'))]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "select\n",
    "    date_part('year',time_stamp)::integer as year,\n",
    "    date_part('week',time_stamp)::integer as week,\n",
    "    min(altitude) as altitude\n",
    "from flyby_altitudes\n",
    "group by\n",
    "    date_part('year',time_stamp),\n",
    "    date_part('week',time_stamp) \n",
    "order by year, week"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53513439-d60a-4a40-8955-f9d140cc686f",
   "metadata": {},
   "source": [
    "Next, find the exact `time_stamp` associated with each nadir using a CTE\n",
    "\n",
    "Due to the speed of Cassini, multiple timestamps are associated with each flyby's min altitude. Without any additional context, the next best thing is to take the average of all the timestamps associated with each nadir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44c9c494-d0fa-4f1a-a8fd-0c7bcbc366a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * postgresql://postgres:***@localhost:5432/enceladus\n",
      "23 rows affected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>time_stamp_avg</th>\n",
       "            <th>alt</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "        <tr>\n",
       "            <td>2005-02-17 03:30:12.119000</td>\n",
       "            <td>1272.075</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2005-03-09 09:08:03.472500</td>\n",
       "            <td>500.370</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2005-07-14 19:55:22.330000</td>\n",
       "            <td>168.012</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2008-03-12 19:06:11.509000</td>\n",
       "            <td>50.292</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2008-08-11 21:06:18.574000</td>\n",
       "            <td>53.353</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2008-10-09 19:06:39.724000</td>\n",
       "            <td>28.576</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2008-10-31 17:14:51.429000</td>\n",
       "            <td>173.044</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2009-11-21 02:09:56.371000</td>\n",
       "            <td>1596.561</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2010-05-18 06:04:40.301000</td>\n",
       "            <td>437.292</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2010-08-13 22:30:51.975000</td>\n",
       "            <td>2555.180</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2010-10-17 10:47:11.762000</td>\n",
       "            <td>98.901</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2010-11-30 11:53:59.049000</td>\n",
       "            <td>45.699</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2010-12-21 01:08:27.146000</td>\n",
       "            <td>48.324</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2011-04-21 18:56:21.275000</td>\n",
       "            <td>3771.195</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2011-10-01 13:52:25.698000</td>\n",
       "            <td>98.898</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2011-10-19 09:22:11.224500</td>\n",
       "            <td>1230.674</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2011-11-06 04:58:53.480500</td>\n",
       "            <td>496.603</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2012-03-27 18:30:08.975000</td>\n",
       "            <td>74.165</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2012-04-14 14:01:37.811000</td>\n",
       "            <td>74.100</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2012-05-02 09:31:28.949000</td>\n",
       "            <td>73.134</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2015-10-14 10:41:28.976500</td>\n",
       "            <td>1844.230</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2015-10-28 15:22:41.550000</td>\n",
       "            <td>49.010</td>\n",
       "        </tr>\n",
       "        <tr>\n",
       "            <td>2015-12-19 17:49:16.113500</td>\n",
       "            <td>5000.200</td>\n",
       "        </tr>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "[(datetime.datetime(2005, 2, 17, 3, 30, 12, 119000), Decimal('1272.075')),\n",
       " (datetime.datetime(2005, 3, 9, 9, 8, 3, 472500), Decimal('500.370')),\n",
       " (datetime.datetime(2005, 7, 14, 19, 55, 22, 330000), Decimal('168.012')),\n",
       " (datetime.datetime(2008, 3, 12, 19, 6, 11, 509000), Decimal('50.292')),\n",
       " (datetime.datetime(2008, 8, 11, 21, 6, 18, 574000), Decimal('53.353')),\n",
       " (datetime.datetime(2008, 10, 9, 19, 6, 39, 724000), Decimal('28.576')),\n",
       " (datetime.datetime(2008, 10, 31, 17, 14, 51, 429000), Decimal('173.044')),\n",
       " (datetime.datetime(2009, 11, 21, 2, 9, 56, 371000), Decimal('1596.561')),\n",
       " (datetime.datetime(2010, 5, 18, 6, 4, 40, 301000), Decimal('437.292')),\n",
       " (datetime.datetime(2010, 8, 13, 22, 30, 51, 975000), Decimal('2555.180')),\n",
       " (datetime.datetime(2010, 10, 17, 10, 47, 11, 762000), Decimal('98.901')),\n",
       " (datetime.datetime(2010, 11, 30, 11, 53, 59, 49000), Decimal('45.699')),\n",
       " (datetime.datetime(2010, 12, 21, 1, 8, 27, 146000), Decimal('48.324')),\n",
       " (datetime.datetime(2011, 4, 21, 18, 56, 21, 275000), Decimal('3771.195')),\n",
       " (datetime.datetime(2011, 10, 1, 13, 52, 25, 698000), Decimal('98.898')),\n",
       " (datetime.datetime(2011, 10, 19, 9, 22, 11, 224500), Decimal('1230.674')),\n",
       " (datetime.datetime(2011, 11, 6, 4, 58, 53, 480500), Decimal('496.603')),\n",
       " (datetime.datetime(2012, 3, 27, 18, 30, 8, 975000), Decimal('74.165')),\n",
       " (datetime.datetime(2012, 4, 14, 14, 1, 37, 811000), Decimal('74.100')),\n",
       " (datetime.datetime(2012, 5, 2, 9, 31, 28, 949000), Decimal('73.134')),\n",
       " (datetime.datetime(2015, 10, 14, 10, 41, 28, 976500), Decimal('1844.230')),\n",
       " (datetime.datetime(2015, 10, 28, 15, 22, 41, 550000), Decimal('49.010')),\n",
       " (datetime.datetime(2015, 12, 19, 17, 49, 16, 113500), Decimal('5000.200'))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "-- flybys table\n",
    "with lows_by_weeks as \n",
    "    (select \n",
    "        date_part('year', time_stamp) as year,\n",
    "        date_part('week', time_stamp) as week,\n",
    "        min(altitude) as alt\n",
    "    from flyby_altitudes\n",
    "    group by \n",
    "        date_part('year', time_stamp),\n",
    "        date_part('week', time_stamp)\n",
    "    ), \n",
    "nadirs as (\n",
    "    select \n",
    "        f.time_stamp,\n",
    "        l.alt\n",
    "    from lows_by_weeks l\n",
    "    inner join flyby_altitudes f\n",
    "    on l.alt = f.altitude\n",
    ")\n",
    "select \n",
    "    min(time_stamp) + (max(time_stamp) - min(time_stamp))/2 time_stamp_avg,\n",
    "    alt\n",
    "from nadirs\n",
    "group by \n",
    "    alt -- don't group by dates a second time\n",
    "order by time_stamp_avg;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16269fc0-bfa6-41e5-8332-6fb90d6c1dd9",
   "metadata": {},
   "source": [
    "duplicates showing up for 2011-10-01 and 2012-04-14??? don't group by dates again in the last query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b04df0-e754-44e8-ba4c-492d218cd3ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
